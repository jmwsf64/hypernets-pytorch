{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z7H0FyAGZlos"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "The purpose of this notebook is to demonstrate how to structure training data and how to enact the interaction between the two networks in a Hyper Network model using PyTorch. A Hyper Network is composed of two Neural Networks; the HyperNet and the TargetNet (sometimes referred to as MainNet). The weights and biases of the TargetNet are the output of the HyperNet, simply rearranged to fit the dimensions of the TargetNet weights and biases tensors.\n",
    "\n",
    "Consider a use case for a computer vision application for a camera with an optical zoom that causes enough image distortion that object detection performance in the corners of the image is drastically reduced. One solution could be to use different CNN models for different zoom levels if local processing and storage resources allow for this. One drawback is that between the specified zoom levels of each CNN model the user will need to select which model leads to more accurate detections. As you can imagine, this is not an ideal solution when distortion is this significant. An alternative solution is to use a HyperNetwork-CNN structure. The training data for this scenario will be generated in the same way, labeling images at specified zoom levels, however the training algorithm will change. The TargetNet will be set as a CNN and a HyperNet as a DNN. The zoom level for a specified image will be used as the HyperNet input, the HyperNet will output all parameters for the CNN, and the back propagation algorithm will tune the HyperNet to produce a more accurate CNN. In other words, we are not training the TargetNet (CNN) to detect objects in images, we are training the HyperNet (DNN) to produce a CNN that will accurately detect objects based on the current zoom level no matter the value. Instead of having, for example, 11 models for different zoom levels {0%, 10%, ..., 100%} and assuming which model to use for levels in between we can set an arbitrary zoom level on our lens as the input to our HyperNet and produce an accurate CNN at run time.\n",
    "\n",
    "# Input Data Generation\n",
    "\n",
    "Before we do anything with Hyper Networks, we first need to create our data arrays. For this demonstration we will create a Long Short Term Memory (LSTM) network that predicts sinusoidal wave forms and use this as our TargetNet. Regular LSTM networks will have poor performance when alterations are made to frequency, and to a lesser extent amplitude, so we will select these two values as the inputs to our HyperNet.\n",
    "\n",
    "The test and validation data sets will be on true sine waves with no added noise. There are (2) test data sets and (2) validation data sets. Each will have (1) set with HyperNet inputs that are found in the training data set, and (1) set with HyperNet inputs that were not in the training data set. In this way, we see how well the trained Hyper Network predicts a true sine wave when only being given noisy sine waves for a parameter set, and also how it predicts a true sine wave with parameters it has never seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9DlmhsWkZloz"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p3fSoO1VZlo2"
   },
   "source": [
    "## Prep\n",
    "\n",
    "As mentioned above, the inputs to the HyperNet will be Amplitude and Frequency. The following variables define the range and number of samples for the Amplitude and Frequency arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1e7HRv-CZlo3"
   },
   "outputs": [],
   "source": [
    "NUM_AMP_PTS = 15\n",
    "MIN_AMP = 0.1\n",
    "MAX_AMP = 0.9\n",
    "\n",
    "NUM_FREQ_PTS = 15\n",
    "MIN_FREQ = 2\n",
    "MAX_FREQ = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p_xrSi4CZlo5"
   },
   "source": [
    "The following variables are used to create the sine waves for all data sets.\n",
    "\n",
    "* `SEQ_LEN` and `PRED_LEN` are used to create input and prediction sequences for the LSTM TargetNet.\n",
    "* `TRAIN_STEP` and `TEST_STEP` define how much to step forward between sequenced data.\n",
    "    * In some demonstrations an `overlap` is defined instead.\n",
    "* `ARRAY_LEN` defines the number of points in the sine waves.\n",
    "* Finally, the last two variables define the number of cycles in the train and test/validation data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xi4m1MIDZlo8"
   },
   "outputs": [],
   "source": [
    "SEQ_LEN = 200\n",
    "PRED_LEN = 1\n",
    "TRAIN_STEP = 5\n",
    "TEST_STEP = 1\n",
    "ARRAY_LEN = 2000\n",
    "NUM_TEST_CYCLES = 5\n",
    "ARRAYS_PER_PARAM_SET = 5\n",
    "NOISE_FACTOR = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oRFH8GJVZlo8"
   },
   "source": [
    "These define the number of arrays in:\n",
    "* The ***N***umber of ***T***est data sets with HyperNet ***T***raining ***P***arameters\n",
    "* The ***N***umber of ***T***est data sets with ***N***ew HyperNet ***P***arameters\n",
    "* The ***N***umber of ***V***alidation data sets with HyperNet ***T***raining ***P***arameters\n",
    "* The ***N***umber of ***V***alidation data sets with ***N***ew HyperNet ***P***arameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J6NRPoruZlo-"
   },
   "outputs": [],
   "source": [
    "NTTP = 5\n",
    "NTNP = 5\n",
    "NVTP = 5\n",
    "NVNP = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7G8c6jDzZlpH"
   },
   "source": [
    "## Sequencing\n",
    "\n",
    "This function will take a sine wave and convert it into LSTM sequences for later batching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bx1e-BZyZlpI"
   },
   "outputs": [],
   "source": [
    "def sequence_array(sine: np.ndarray, step: int) -> tuple[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Convert sinusoidal arrays to LSTM sequences and predictions\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sine : np.ndarray\n",
    "        array of sinusoidal y-values\n",
    "    step : int\n",
    "        forward step for data\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        stack of input sequences\n",
    "    np.ndarray\n",
    "        stack of prediction arrays\n",
    "    \"\"\"\n",
    "    seqs, preds, start = None, None, 0\n",
    "    for _ in range(int((ARRAY_LEN - SEQ_LEN - PRED_LEN) / step) + 1):\n",
    "        seq = sine[start : start + SEQ_LEN].reshape(1, SEQ_LEN, 1)\n",
    "        pred = sine[start + SEQ_LEN : start + SEQ_LEN + PRED_LEN].reshape(1,)  # fmt:skip\n",
    "        seqs = seq if seqs is None else np.vstack([seqs, seq])\n",
    "        preds = pred if preds is None else np.vstack([preds, pred])\n",
    "        start += step\n",
    "    return seqs, preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sy5nOSstZlpK"
   },
   "source": [
    "## Training Arrays\n",
    "\n",
    "Here we create the noisy sine waves that are used for the training data set. We loop over the Amplitude and Frequency sampling arrays and record them separately from the sine wave data. Then we create and sequence the noisy sine waves and then save the arrays in a dictionary.\n",
    "\n",
    "Once all noisy sine waves are created and sequenced, we save the list of dictionaries of arrays to a compressed NumPy file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f9F16TtMZlpL",
    "outputId": "8d3453f2-3a61-4515-de12-c4caf618ec6a"
   },
   "outputs": [],
   "source": [
    "A = np.linspace(MIN_AMP, MAX_AMP, NUM_AMP_PTS)\n",
    "F = np.linspace(MIN_FREQ, MAX_FREQ, NUM_FREQ_PTS)\n",
    "t = np.linspace(0, 2 * np.pi, ARRAY_LEN)\n",
    "\n",
    "TRAIN_DATA, count = [], 0\n",
    "for amp in A:\n",
    "    for f in F:\n",
    "        hyper_params = np.array([amp, f])\n",
    "        for i in range(ARRAYS_PER_PARAM_SET):\n",
    "            sine = amp * np.sin(f * t) + (amp * NOISE_FACTOR * (np.random.rand(*t.shape) - 0.5))\n",
    "            seqs, preds = sequence_array(sine, TRAIN_STEP)\n",
    "            TRAIN_DATA.append({\"hx\": hyper_params, \"tx\": seqs, \"tyhat\": preds})\n",
    "            count += 1\n",
    "            print(f\"Created and sequenced {count} arrays\", end=\"\\r\")\n",
    "\n",
    "print(f\"Created and sequenced {count} arrays\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gdrhi3RMZlpQ"
   },
   "source": [
    "## Test and Validation (Training HyperNet Parameters)\n",
    "\n",
    "Now we create the test and validation data set with HyperNet input values that were found in the training data set created above.\n",
    "\n",
    "We randomly select different values of Amplitude and Frequency and create a true sine wave representation for those values.\n",
    "\n",
    "For a true representation of testing and validating our model, there can be no values in one data set that are also found in the other.\n",
    "\n",
    "Once all arrays are created and sequenced, we save them to the file names defined at the beginning of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_QqzUs7EZlpQ"
   },
   "outputs": [],
   "source": [
    "A_sels, F_sels, TTP_DATA, VTP_DATA = [], [], [], []\n",
    "\n",
    "for _ in range(NTTP):\n",
    "\n",
    "    # select random A and F from HyperNet training parameters\n",
    "    sel_A = np.random.randint(0, len(A) - 1, (100,))\n",
    "    sel_F = np.random.randint(0, len(F) - 1, (100,))\n",
    "    sel_A = [x for x in sel_A if x not in A_sels][0]\n",
    "    sel_F = [x for x in sel_F if x not in F_sels][0]\n",
    "    A_sels.append(sel_A)\n",
    "    F_sels.append(sel_F)\n",
    "\n",
    "    # create tensors\n",
    "    hyper_params = np.array([A[sel_A], F[sel_F]])\n",
    "    sine = A[sel_A] * np.sin(F[sel_F] * t)\n",
    "\n",
    "    # sequence sine wave array\n",
    "    seqs, preds = sequence_array(sine, TRAIN_STEP)\n",
    "\n",
    "    # append data set\n",
    "    TTP_DATA.append({\"hx\": hyper_params, \"tx\": seqs, \"tyhat\": preds})\n",
    "\n",
    "for _ in range(NVTP):\n",
    "\n",
    "    # select random A and F from training HyperNet Parameters\n",
    "    sel_A = np.random.randint(0, len(A) - 1, (100,))\n",
    "    sel_F = np.random.randint(0, len(F) - 1, (100,))\n",
    "    sel_A = [x for x in sel_A if x not in A_sels][0]\n",
    "    sel_F = [x for x in sel_F if x not in F_sels][0]\n",
    "    A_sels.append(sel_A)\n",
    "    F_sels.append(sel_F)\n",
    "\n",
    "    # create tensors\n",
    "    hyper_params = np.array([A[sel_A], F[sel_F]])\n",
    "    sine = A[sel_A] * np.sin(F[sel_F] * t)\n",
    "\n",
    "    # sequence sine wave array\n",
    "    seqs, preds = sequence_array(sine, TEST_STEP)\n",
    "\n",
    "    # append data set\n",
    "    VTP_DATA.append({\"hx\": hyper_params, \"tx\": seqs, \"tyhat\": preds})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nN7Zw4F6ZlpS"
   },
   "source": [
    "## Test and Validation (New HyperNet Parameters)\n",
    "\n",
    "Now we create the test and validation data sets for values that were not included in the training data set. We use NumPy's `rand()` funnction to generate 1000 different values and select the first one that was not in the training data set and not already selected previously.\n",
    "\n",
    "Once all arrays are created and sequenced, we save them to the file names defined at the beginning of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XhcAn2hjZlpT"
   },
   "outputs": [],
   "source": [
    "min_A, max_A = min(A), max(A)\n",
    "min_F, max_F = min(F), max(F)\n",
    "\n",
    "A_sels, F_sels, TNP_DATA, VNP_DATA = [], [], [], []\n",
    "\n",
    "for _ in range(NTNP):\n",
    "\n",
    "    # select random A and F not in HyperNet training parameters\n",
    "    sel_A = np.random.rand(1000)\n",
    "    sel_F = np.random.rand(1000) * max_F\n",
    "    sel_A = [x for x in sel_A if x not in A and x not in A_sels and min_A < x < max_A][0]\n",
    "    sel_F = [x for x in sel_F if x not in F and x not in F_sels and min_F < x < max_F][0]\n",
    "    A_sels.append(sel_A)\n",
    "    F_sels.append(sel_F)\n",
    "\n",
    "    # create tensors\n",
    "    hyper_params = np.array([sel_A, sel_F])\n",
    "    sine = sel_A * np.sin(sel_F * t)\n",
    "\n",
    "    # sequence sine wave array\n",
    "    seqs, preds = sequence_array(sine, TRAIN_STEP)\n",
    "\n",
    "    # append data set\n",
    "    TNP_DATA.append({\"hx\": hyper_params, \"tx\": seqs, \"tyhat\": preds})\n",
    "\n",
    "\n",
    "for _ in range(NVNP):\n",
    "\n",
    "    # select random A and F not in HyperNet training parameters\n",
    "    sel_A = np.random.rand(1000)\n",
    "    sel_F = np.random.rand(1000) * max_F\n",
    "    sel_A = [x for x in sel_A if x not in A and x not in A_sels and min_A < x < max_A][0]\n",
    "    sel_F = [x for x in sel_F if x not in F and x not in F_sels and min_F < x < max_F][0]\n",
    "    A_sels.append(sel_A)\n",
    "    F_sels.append(sel_F)\n",
    "\n",
    "    # create tensors\n",
    "    hyper_params = np.array([sel_A, sel_F])\n",
    "    sine = sel_A * np.sin(sel_F * t)\n",
    "\n",
    "    # sequence sine wave array\n",
    "    seqs, preds = sequence_array(sine, TEST_STEP)\n",
    "\n",
    "    # append data set\n",
    "    VNP_DATA.append({\"hx\": hyper_params, \"tx\": seqs, \"tyhat\": preds})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data to PyTorch\n",
    "\n",
    "The following custom Dataset class is used to batch the train and test data sets with a Dataloader. `x` is the TargetNet input tensor, and `yhat` is the TargetNet output target values tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\")\n",
    "BATCH_SIZE = 25\n",
    "\n",
    "\n",
    "class RNNDataset(Dataset):\n",
    "\n",
    "    def __init__(self, x: torch.Tensor, yhat: torch.Tensor) -> None:\n",
    "        super().__init__()\n",
    "        self.x = x\n",
    "        self.yhat = yhat\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx) -> tuple[torch.Tensor]:\n",
    "        return self.x[idx], self.yhat[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will parse the loaded datasets. It will convert all NumPy Arrays to PyTorch Tensors and ensure that the tensor is on the correct device and of a compatible data format. With this function defined we parse the training and test data sets and shuffle the training data set but not the test data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_input_dataset(dataset: list, sh: bool) -> list:\n",
    "    \"\"\"\n",
    "    load RNN data in dataset with `RNNDataset` and `DataLoader`\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : list\n",
    "        list of data arrays\n",
    "    sh : bool\n",
    "        shuffle Dataset if True, else False\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        parsed dataset\n",
    "    \"\"\"\n",
    "    for i, ds in enumerate(dataset):\n",
    "        hx = torch.from_numpy(ds[\"hx\"]).to(DEVICE).float()\n",
    "        tx = torch.from_numpy(ds[\"tx\"]).to(DEVICE).float()\n",
    "        tyhat = torch.from_numpy(ds[\"tyhat\"]).to(DEVICE).float()\n",
    "        rnn_data = DataLoader(\n",
    "            RNNDataset(tx, tyhat), batch_size=BATCH_SIZE, shuffle=sh, drop_last=True\n",
    "        )\n",
    "        dataset[i] = [hx, rnn_data]\n",
    "    return dataset\n",
    "\n",
    "\n",
    "TRAIN_DATA = parse_input_dataset(TRAIN_DATA, True)\n",
    "TTP_DATA = parse_input_dataset(TTP_DATA, False)\n",
    "TNP_DATA = parse_input_dataset(TNP_DATA, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modifying TargetNet Parameters\n",
    "\n",
    "The TargetNet parameters have to be modified in different ways depending on if the model is being trained or is being used for normal inference.\n",
    "\n",
    "## During training\n",
    "\n",
    "We cannot directly modify the TargetNet parameters during training. If we attempted this, PyTorch will raise an exception that parameters were modified by an in-place operation. To run the TargetNet with the parameters from the HyperNet (`hy`), we can use `torch.func.functional_call(targetNet, tn_params, tx)` where `targetNet` is the TargetNet model, `tn_params` is a dictionary with key-value pairs of the parameter name and the new tensor, and `tx` is the TargetNet input tensor.\n",
    "\n",
    "***Note:*** If you are unfamiliar, `math.prod()` is similar to `sum()`, but multiplies all values of an iterable together.\n",
    "\n",
    "```python\n",
    "# collect new parameters in a dict with name of parameter as key\n",
    "idx, tn_params = 0, {}\n",
    "for n, p in targetNet.named_parameters():\n",
    "    tn_params[n] = hy[idx : idx + math.prod(p.shape)].reshape(*p.shape)\n",
    "    idx += math.prod(p.shape)\n",
    "\n",
    "# use PyTorch's functional_call\n",
    "ty = torch.func.functional_call(targetNet, tn_params, tx)\n",
    "```\n",
    "\n",
    "## During normal inference operation\n",
    "\n",
    "We cannot use the above method to modify TargetNet parameters during normal inference because using `functional_call()` will throw raise an exception when not training. However, not that we are not training, we can modify the parameter tensors in-place without raising an exception. Then, we simply use the `forward()` method of the TargetNet.\n",
    "\n",
    "```python\n",
    "# modify parameters in place\n",
    "idx = 0\n",
    "for p in targetNet.parameters():\n",
    "    p[:] = hy[idx : idx + math.prod(p.shape)].reshape(*p.shape)\n",
    "    idx += math.prod(p.shape)\n",
    "\n",
    "# use TargetNet's forward method\n",
    "ty = targetNet(tx)\n",
    "```\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import plotly\n",
    "\n",
    "from torch import optim\n",
    "from torch.func import functional_call\n",
    "from torch.nn import Module, Sequential, Linear, LSTM, ReLU, Tanh, MSELoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Parameters\n",
    "\n",
    "The following constants are used to define the TargetNet LSTM and the HyperNet DNN.\n",
    "\n",
    "`HYPERNET_NODES` is a list of the number of nodes in each layer, except for the output layer to the TargetNet.\n",
    "\n",
    "`HYPERNET_ACTS` is a list of activation functions for each hidden layer *and* the output layer to the TargetNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_LSTM_LAYERS = 3\n",
    "LSTM_IN_DIM = 1\n",
    "LSTM_HIDDEN_DIM = 10\n",
    "LSTM_OUT_DIM = 1\n",
    "\n",
    "HYPERNET_NODES = [2, 8, 12, 12, 8, 2]\n",
    "HYPERNET_ACTS = [ReLU(), ReLU(), ReLU(), ReLU(), ReLU(), Tanh()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Setup\n",
    "\n",
    "## Parameters\n",
    "\n",
    "The following constants are values used to configure the training settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 15\n",
    "LEARN_RATE = 1e-4\n",
    "LOSS_FN = MSELoss()\n",
    "MODEL_NAME = \"sinusoidal_hypernet.pt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "This function will train the HyperNetwork model for a single epoch for a given HyperNet input array `hx`. Note that as described at the top of the notebook, we create dictionaries of the named parameter tensors with the output of the HyperNet. Once these are created, we run the TargNet on the batched noisy sine wave sequences using `functional_call()`.\n",
    "\n",
    "The loss is calculated and summed across batches and returned to the main training loop below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    hyperNet: Sequential,\n",
    "    targetLSTM: LSTM,\n",
    "    targetSeq: Sequential,\n",
    "    hx: torch.Tensor,\n",
    "    t_data: DataLoader,\n",
    "    batch_size: int,\n",
    "    loss_fn: Module,\n",
    "    device: torch.device,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Train HyperNetwork model for a given epoch\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    hyperNet : Sequential\n",
    "        HyperNetwork described as a PyTorch Sequential model\n",
    "    targetLSTM : LSTM\n",
    "        TargetNetwork LSTM portion\n",
    "    targetSeq : Sequential\n",
    "        TargetNetwork Sequential portion\n",
    "    hx : torch.Tensor\n",
    "        HyperNetwork input tensor\n",
    "    t_data : DataLoader\n",
    "        Batched training data\n",
    "    batch_size : int\n",
    "        Training data batch size\n",
    "    loss_fn : Module\n",
    "        PyTorch defined loss function\n",
    "    device : torch.device\n",
    "        PyTorch defined computation device\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        calculated loss tensor\n",
    "    \"\"\"\n",
    "\n",
    "    # hidden/cell state dimensions\n",
    "    hc_state_dim = (targetLSTM.num_layers, batch_size, targetLSTM.hidden_size)\n",
    "\n",
    "    # run HyperNet\n",
    "    hy = hyperNet(hx)\n",
    "\n",
    "    # collect TargetNet weights and biases in dicts\n",
    "    idx, tn_params = 0, {}\n",
    "    for n, p in targetLSTM.named_parameters():\n",
    "        tn_params[n] = hy[idx : idx + math.prod(p.shape)].reshape(*p.shape)\n",
    "        idx += math.prod(p.shape)\n",
    "    tns_params = {}\n",
    "    for n, p in targetSeq.named_parameters():\n",
    "        tns_params[n] = hy[idx : idx + math.prod(p.shape)].reshape(*p.shape)\n",
    "        idx += math.prod(p.shape)\n",
    "\n",
    "    # run LSTM data in batches\n",
    "    loss = 0\n",
    "    for _, batch in enumerate(t_data):\n",
    "        tx, tyhat = batch[0].to(device), batch[1].to(device)\n",
    "        h0 = torch.zeros(*hc_state_dim).to(device)\n",
    "        c0 = torch.zeros(*hc_state_dim).to(device)\n",
    "        ty, _ = functional_call(targetLSTM, tn_params, (tx, (h0, c0)))\n",
    "        ty = functional_call(targetSeq, tns_params, ty[:, -1, :])\n",
    "        loss += loss_fn(ty, tyhat)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to the `train_epoch()` function defined above, this function will perform the same operation but with the test data set passed. Note that `functional_call()` is still used to run the TargetNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(\n",
    "    hyperNet: Sequential,\n",
    "    targetLSTM: LSTM,\n",
    "    targetSeq: Sequential,\n",
    "    vhx: torch.Tensor,\n",
    "    vt_data: DataLoader,\n",
    "    batch_size: int,\n",
    "    loss_fn: Module,\n",
    "    device: torch.device,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Test HyperNetwork model for a given epoch\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    hyperNet : Sequential\n",
    "        HyperNetwork described as a PyTorch Sequential model\n",
    "    targetLSTM : LSTM\n",
    "        TargetNetwork LSTM portion\n",
    "    targetSeq : Sequential\n",
    "        TargetNetwork Sequential portion\n",
    "    vhx : torch.Tensor\n",
    "        HyperNetwork validation input tensor\n",
    "    vt_data : DataLoader\n",
    "        Batched validation data\n",
    "    batch_size : int\n",
    "        Validation data batch size\n",
    "    loss_fn : Module\n",
    "        PyTorch defined loss function\n",
    "    device : torch.device\n",
    "        PyTorch defined computation device\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        calculated loss for this epoch\n",
    "    \"\"\"\n",
    "\n",
    "    hc_state_dim = (targetLSTM.num_layers, batch_size, targetLSTM.hidden_size)\n",
    "\n",
    "    loss = 0\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # run HyperNet\n",
    "        vhy = hyperNet(vhx)\n",
    "\n",
    "        # collect TargetNet weights and biases in dicts\n",
    "        idx, vtn_params = 0, {}\n",
    "        for n, p in targetLSTM.named_parameters():\n",
    "            vtn_params[n] = vhy[idx : idx + math.prod(p.shape)].reshape(*p.shape)\n",
    "            idx += math.prod(p.shape)\n",
    "        vtns_params = {}\n",
    "        for n, p in targetSeq.named_parameters():\n",
    "            vtns_params[n] = vhy[idx : idx + math.prod(p.shape)].reshape(*p.shape)\n",
    "            idx += math.prod(p.shape)\n",
    "\n",
    "        # run LSTM data in batches\n",
    "        for _, batch in enumerate(vt_data):\n",
    "            vtx, vtyhat = batch[0].to(device), batch[1].to(device)\n",
    "            vh0 = torch.zeros(*hc_state_dim).to(device)\n",
    "            vc0 = torch.zeros(*hc_state_dim).to(device)\n",
    "            vty, _ = functional_call(targetLSTM, vtn_params, (vtx, (vh0, vc0)))\n",
    "            vty = functional_call(targetSeq, vtns_params, vty[:, -1, :])\n",
    "            loss += loss_fn(vty, vtyhat)\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TargetNet\n",
    "\n",
    "Now that our data is loaded and the train and test functions are defined, we have to create the Hyper Network models. We must create the TargetNet first so that we know the output dimension of the HyperNet. Here we create an LSTM with the values defined at the beginning of this notebook and a Linear layer and activation function also defined above. These two are tracked in separate variables to properly use in PyTorch but should be considered together as the TargetNet.\n",
    "\n",
    "Once these two models are created, we need to calculate total number of parameters in the TargetNet and make sure that all are set to not require gradient so that they are not accidentally picked up by the backpropagation operations.\n",
    "\n",
    "Finally we move both models to the inference device selected at the beginning of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create TargetNet modules\n",
    "targetLSTM = LSTM(LSTM_IN_DIM, LSTM_HIDDEN_DIM, N_LSTM_LAYERS, batch_first=True, device=DEVICE)\n",
    "targetSeq = Sequential(Linear(LSTM_HIDDEN_DIM, LSTM_OUT_DIM), Tanh()).to(DEVICE)\n",
    "\n",
    "# get number of parameters in TargetNet\n",
    "target_params = 0\n",
    "for p in targetLSTM.parameters():\n",
    "    target_params += math.prod(p.shape)\n",
    "    p.requires_grad = False\n",
    "for p in targetSeq.parameters():\n",
    "    target_params += math.prod(p.shape)\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HyperNet\n",
    "\n",
    "Now that we know the total number of parameters in the TargetNet, we can create the HyperNet DNN. First we append the number of parameters in the TargetNet to the HyperNet nodes list, then create a Sequential model of alternating Linear layers and Activation functions defined above.\n",
    "\n",
    "Finally, we also move the model to the selected inference device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HYPERNET_NODES.append(target_params)\n",
    "layers = []\n",
    "for i, act in enumerate(HYPERNET_ACTS):\n",
    "    layers.append(Linear(HYPERNET_NODES[i], HYPERNET_NODES[i + 1]))\n",
    "    layers.append(act)\n",
    "hyperNet = Sequential(*layers).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Hyper Network\n",
    "\n",
    "And finally we can start training the HyperNet! First we pass the HyperNet parameters to the optimizer. Note that the optimizer does ***not*** see the TargetNet parameters because we aren't attempting to create an LSTM that can generate sine waves, we are creating a DNN that can *tune* an LSTM to create sine waves of varying Amplitude and Frequency.\n",
    "\n",
    "We also create a tuple of the dimensions that will be used for the LSTM Hidden and Cell state arrays.\n",
    "\n",
    "For each epoch, we iterate over the training data sets and back propagate with the loss calculated in the `train_epoch()` function defined above. We then calculate test loss for the test data set with training HyperNet inputs and the test data set with unseen HyperNet inputs.\n",
    "\n",
    "We output the model that has the best training loss and print out each loss value tracked during training at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create optimizer\n",
    "optimizer = optim.Adam(hyperNet.parameters(), lr=LEARN_RATE)\n",
    "\n",
    "# track loss over epochs\n",
    "best_loss = torch.inf\n",
    "loss, ttp_loss, tnp_loss = [], [], []\n",
    "\n",
    "# dimension of LSTM hidden/cell states\n",
    "hc_state_dim = (targetLSTM.num_layers, BATCH_SIZE, targetLSTM.hidden_size)\n",
    "\n",
    "# iterate over epochs\n",
    "for i in range(EPOCHS):\n",
    "\n",
    "    # train HyperNet for this epoch\n",
    "    loss_i = 0\n",
    "    for hx, t_data in TRAIN_DATA:\n",
    "\n",
    "        # run epoch\n",
    "        optimizer.zero_grad()\n",
    "        loss_b = train_epoch(\n",
    "            hyperNet, targetLSTM, targetSeq, hx, t_data, BATCH_SIZE, LOSS_FN, DEVICE\n",
    "        )\n",
    "\n",
    "        # back propagate HyperNet\n",
    "        loss_b.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # track loss for HyperNet input set\n",
    "        loss_i += loss_b.item()\n",
    "\n",
    "    # test model with training parameters\n",
    "    ttp_loss_i = 0\n",
    "    for vhx, vt_data in TTP_DATA:\n",
    "        ttp_loss_i += test_epoch(\n",
    "            hyperNet, targetLSTM, targetSeq, vhx, vt_data, BATCH_SIZE, LOSS_FN, DEVICE\n",
    "        )\n",
    "\n",
    "    # test model with new parameters\n",
    "    tnp_loss_i = 0\n",
    "    for vhx, vt_data in TNP_DATA:\n",
    "        tnp_loss_i += test_epoch(\n",
    "            hyperNet, targetLSTM, targetSeq, vhx, vt_data, BATCH_SIZE, LOSS_FN, DEVICE\n",
    "        )\n",
    "\n",
    "    # track loss for epoch\n",
    "    loss.append(loss_i)\n",
    "    ttp_loss.append(ttp_loss_i)\n",
    "    tnp_loss.append(tnp_loss_i)\n",
    "\n",
    "    # save model if it has lowest loss\n",
    "    if loss_i < best_loss:\n",
    "        best_loss = loss_i\n",
    "        hyperNet = hyperNet.cpu()\n",
    "        torch.save(hyperNet.state_dict(), MODEL_NAME)\n",
    "        hyperNet = hyperNet.to(DEVICE)\n",
    "\n",
    "    # print training progress\n",
    "    print(\n",
    "        f\"Epoch: {i+1:0>2} | Loss: {loss_i:.3e} | \"\n",
    "        f\"Best Loss: {best_loss:.3e} | \"\n",
    "        f\"TTP Loss: {ttp_loss_i:.3e} | \"\n",
    "        f\"TNP Loss: {tnp_loss_i:.3e}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Loss History\n",
    "\n",
    "Now that training has concluded, let's plot the loss history over each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fig = go.Figure()\n",
    "loss_fig.add_trace(\n",
    "    go.Scatter(x=torch.arange(len(loss)) + 1, y=loss, name=\"Loss\", mode=\"lines\", showlegend=True)\n",
    ")\n",
    "loss_fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=torch.arange(len(ttp_loss)) + 1,\n",
    "        y=ttp_loss,\n",
    "        name=\"TTP Loss\",\n",
    "        mode=\"lines\",\n",
    "        showlegend=True,\n",
    "    )\n",
    ")\n",
    "loss_fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=torch.arange(len(tnp_loss)) + 1,\n",
    "        y=tnp_loss,\n",
    "        name=\"TNP Loss\",\n",
    "        mode=\"lines\",\n",
    "        showlegend=True,\n",
    "    )\n",
    ")\n",
    "loss_fig.update_layout(\n",
    "    title=\"Sinusoidal HyperNet Loss\",\n",
    "    yaxis={\"title\": \"Loss\"},\n",
    "    xaxis={\"title\": \"Epoch\"},\n",
    "    hovermode=\"x unified\",\n",
    ")\n",
    "\n",
    "loss_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation\n",
    "\n",
    "Now we begin the validation process. First we load the model that was saved during the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperNet.load_state_dict(torch.load(MODEL_NAME, weights_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will act as the `forward()` function for our overall Hyper Network. The name was specifically chosen to match the name used by PyTorch for their models.\n",
    "\n",
    "Note that unlike the training loop, we are not collecting dictionaries of tensors to use as a substiture for the TargetNet parameters. We are instead modifying the values of these tensors in place after we run the HyperNet.\n",
    "\n",
    "We also use the `forward()` method of the TargetNet models, rather than using `functional_call()` like when we were training the HyperNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(\n",
    "    hyperNet: Sequential,\n",
    "    targetLSMT: LSTM,\n",
    "    targetSeq: Sequential,\n",
    "    hx: torch.Tensor,\n",
    "    tx: torch.Tensor,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Forward calculation for HyperNetwork and TargetNetwork in normal\n",
    "    operation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    hyperNet : Sequential\n",
    "        HyperNetwork defined as a PyTorch Sequential\n",
    "    targetLSMT : LSTM\n",
    "        TargetNetwork LSTM portion\n",
    "    targetSeq : Sequential\n",
    "        TargetNetwork Sequential portion\n",
    "    hx : torch.Tensor\n",
    "        HyperNetwork input tensor\n",
    "    tx : torch.Tensor\n",
    "        TargetNetwork input tensor\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        Output array from TargetNetwork\n",
    "    \"\"\"\n",
    "\n",
    "    hy = hyperNet(hx)\n",
    "\n",
    "    idx = 0\n",
    "    for p in targetLSMT.parameters():\n",
    "        p[:] = hy[idx : idx + math.prod(p.shape)].reshape(*p.shape)\n",
    "        idx += math.prod(p.shape)\n",
    "    for p in targetSeq.parameters():\n",
    "        p[:] = hy[idx : idx + math.prod(p.shape)].reshape(*p.shape)\n",
    "        idx += math.prod(p.shape)\n",
    "\n",
    "    hc_dims = (targetLSMT.num_layers, tx.shape[0], targetLSMT.hidden_size)\n",
    "    h0 = torch.zeros(*hc_dims).to(DEVICE)\n",
    "    c0 = torch.zeros(*hc_dims).to(DEVICE)\n",
    "\n",
    "    y, _ = targetLSMT(tx, (h0, c0))\n",
    "    y = targetSeq(y[:, -1, :])\n",
    "\n",
    "    return y.detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is similar to the `parse_input_dataset()` function defined above. We still ensure that each NumPy array is converted to a PyTorch tensor on the selected inference device and of a compatible data format. In addition, we call the `forward()` function defined in the above cell to process the results and include the Hyper Network output array in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_validation_dataset(\n",
    "    dataset: list, hyperNet: Sequential, targetLSMT: LSTM, targetSeq: Sequential\n",
    ") -> list:\n",
    "    \"\"\"\n",
    "    Load RNN data in dataset with `RNNDataset` and `DataLoader`\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : list\n",
    "        list of data arrays\n",
    "    hyperNet : Sequential\n",
    "        HyperNetwork defined as a PyTorch Sequential\n",
    "    targetLSMT : LSTM\n",
    "        TargetNetwork LSTM portion\n",
    "    targetSeq : Sequential\n",
    "        TargetNetwork Sequential portion\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        List of validation results after inference on input data\n",
    "    \"\"\"\n",
    "    for i, ds in enumerate(dataset):\n",
    "        hx = torch.from_numpy(ds[\"hx\"]).to(DEVICE).float()\n",
    "        tx = torch.from_numpy(ds[\"tx\"]).to(DEVICE).float()\n",
    "        tyhat = torch.from_numpy(ds[\"tyhat\"]).to(DEVICE).float()\n",
    "        ty = forward(hyperNet, targetLSMT, targetSeq, hx, tx)\n",
    "        dataset[i] = [hx, tx, ty, tyhat]\n",
    "    return dataset\n",
    "\n",
    "\n",
    "VTP_DATA = parse_validation_dataset(VTP_DATA, hyperNet, targetLSTM, targetSeq)\n",
    "VNP_DATA = parse_validation_dataset(VNP_DATA, hyperNet, targetLSTM, targetSeq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot our results to see how well the HyperNet can predict true sine waves for HyperNet inputs that were included in the training data set and HyperNet inputs that were *not* included in the training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = plotly.colors.qualitative.Plotly\n",
    "color_count = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we plot the results with the validation data set of true sine waves for HyperNet inputs that were included in the training data set and see how well the model predicts the sine waves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshape = (-1,)\n",
    "\n",
    "vtp_fig = go.Figure()\n",
    "vtp_fig.update_layout(\n",
    "    title=\"Training Parameter Validation\", yaxis={\"title\": \"Amplitude\"}, xaxis={\"title\": \"time\"}\n",
    ")\n",
    "for i, (hx, tx, ty, tyhat) in enumerate(VTP_DATA):\n",
    "\n",
    "    tyhat = tyhat.cpu().reshape(*reshape)\n",
    "    ty = ty.cpu().reshape(*reshape)\n",
    "    p_set = f\"HN Set {i+1}\"\n",
    "    p_hover = \"<br>    \".join([f\"{x:.3e}\" for x in hx.cpu().numpy()])\n",
    "\n",
    "    vtp_fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=torch.arange(len(tx)),\n",
    "            y=tyhat.cpu(),\n",
    "            line={\"color\": colors[color_count]},\n",
    "            name=\"True\",\n",
    "            showlegend=True,\n",
    "            legendgroup=p_set,\n",
    "            legendgrouptitle_text=p_set,\n",
    "            hovertemplate=f\"HyperNet Inputs:<br>    {p_hover}<br>\" \"<br>t: %{x}\" \"<br>a: %{y}\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    vtp_fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=torch.arange(len(tx)),\n",
    "            y=ty,\n",
    "            line={\"color\": colors[color_count], \"dash\": \"dash\"},\n",
    "            name=\"Prediction\",\n",
    "            showlegend=True,\n",
    "            legendgroup=p_set,\n",
    "            legendgrouptitle_text=p_set,\n",
    "            hovertemplate=f\"HyperNet Inputs:<br>    {p_hover}<br>\" \"<br>t: %{x}\" \"<br>a: %{y}\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    color_count += 1\n",
    "    if color_count == len(colors):\n",
    "        color_count = 0\n",
    "\n",
    "vtp_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, our prediction is not too bad! There is certainly room for improvement.\n",
    "\n",
    "Now let's see the results on the validation data set with HyperNet inputs that our model has never seen before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vnp_fig = go.Figure()\n",
    "vnp_fig.update_layout(\n",
    "    title=\"New Parameter Validation\",\n",
    "    yaxis={\"title\": \"Amplitude\"},\n",
    "    xaxis={\"title\": \"time\"},\n",
    ")\n",
    "for i, (hx, tx, ty, tyhat) in enumerate(VNP_DATA):\n",
    "\n",
    "    tyhat = tyhat.cpu().reshape(*reshape)\n",
    "    ty = ty.cpu().reshape(*reshape)\n",
    "    p_set = f\"HN Set {i+1}\"\n",
    "    p_hover = \"<br>    \".join([f\"{x:.3e}\" for x in hx.cpu().numpy()])\n",
    "\n",
    "    vnp_fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=torch.arange(len(tx)),\n",
    "            y=tyhat,\n",
    "            line={\"color\": colors[color_count]},\n",
    "            name=\"True\",\n",
    "            showlegend=True,\n",
    "            legendgroup=p_set,\n",
    "            legendgrouptitle_text=p_set,\n",
    "            hovertemplate=f\"HyperNet Inputs:<br>    {p_hover}<br>\" \"<br>t: %{x}\" \"<br>a: %{y}\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    vnp_fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=torch.arange(len(tx)),\n",
    "            y=ty,\n",
    "            line={\"color\": colors[color_count], \"dash\": \"dash\"},\n",
    "            name=\"Prediction\",\n",
    "            showlegend=True,\n",
    "            legendgroup=p_set,\n",
    "            legendgrouptitle_text=p_set,\n",
    "            hovertemplate=f\"HyperNet Inputs:<br>    {p_hover}<br>\" \"<br>t: %{x}\" \"<br>a: %{y}\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    color_count += 1\n",
    "    if color_count == len(colors):\n",
    "        color_count = 0\n",
    "\n",
    "vnp_fig.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
